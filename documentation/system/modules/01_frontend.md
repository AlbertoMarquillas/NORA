## Module: `frontend/`

### 1. Definition

The `frontend/` module is the **graphical user interface (GUI)** of the NORA system. It is the only visible and interactive layer for the human user and serves as the main entry and output point for interaction with the assistant.

This module runs as a single-page web application (SPA) either in a browser or on a touchscreen connected to the Raspberry Pi. It is built to operate in real-time, ensuring smooth interaction cycles between the user and the backend system.

Its primary roles include:

* **Rendering the system state** in a form that is intuitive and understandable to a human user.
* **Emitting and handling events**, such as manual commands or gesture-based triggers.
* **Visualizing data and system responses** coming from various subsystems including voice, sensors, posture analysis, and context-aware agents.

The frontend is **reactive and role-sensitive**: its components dynamically adapt depending on the current system state and the authenticated user’s access level. The GUI is designed to be modular, accessible, and minimalist, with a focus on usability and responsiveness across different devices.

It also incorporates a **role-based access control (RBAC)** layer, distinguishing between administrator, registered user, and guest modes. Depending on the role, different interface modules, settings, and data visibility levels are enabled or restricted.

The administrator role is primarily responsible for controlling and configuring the system. Registered users and guests interact with NORA mainly through a chat interface, which complements the primary voice- and sensor-based interaction model. The difference between users and guests lies in the ability to store personal data such as agendas or preferences—features only available to authenticated users. Guests have ephemeral sessions with restricted capabilities.

The frontend does not directly access physical hardware or processing modules. Instead, it communicates solely through the backend, which aggregates data and acts as a gateway to subsystems like vision, voice, and hardware control.

---

## 2. Functionality

1. **Display current system state**
   Display the current FSM state and contextual indicators (e.g., "NORA is listening", "NORA is idle") through dynamic UI elements.

2. **Emit events to the system**
   Allow the user to trigger system events via on-screen buttons, menu actions, or gesture controls. All events are transmitted to the backend for processing.

3. **Render chat interface (optional interaction)**
   Provide a textual chat interface to communicate with NORA. This feature is secondary and complements the primary voice interaction model.

4. **Show voice and sensor-based outputs**
   Present messages, alerts, or prompts generated by the voice subsystem, sensor inputs, or internal decisions. Text may accompany audio replies.

5. **Provide visual feedback in real time**
   Highlight recognition activity (e.g., waveform animation while listening), display interaction status, and reflect successful or failed actions.

6. **Support animations and visual transitions**
   Use animations to enhance UX, indicate state changes, or visually represent emotional or functional responses from the system.

7. **Manage user roles and access levels**
   Adjust available interface options based on the logged-in user's role:

   * **Admin**: Full dashboard access, diagnostics, configuration tools, live logs, FSM control. Can power on/off individual modules, execute testing scripts, and modify internal system configurations.
   * **User**: Chat access, voice interaction, basic history, and access to personal agenda or preferences.
   * **Guest**: Basic chat and voice interaction with no persistence or access to private settings.

8. **Enable configuration and maintenance (admin only)**
   Allow system diagnostics, manual test triggers, subsystem restarts, selective module shutdown/startup, script execution for hardware or logic validation, and internal configuration updates.

9. **Optional access to system history and logs**
   For authorized users, provide access to previously stored system logs, command history, and statistical usage data.

## 3. Notes and Considerations

* The frontend is not intended to be the primary mode of interaction for regular users; its main role is complementary to voice commands and sensor-based triggers.

* The chat interface is optional and secondary, primarily useful for debugging, development, or as a fallback method of interaction in noisy environments.

* Administrative features must be protected by authentication and should include safeguards to prevent accidental disruption (e.g., disabling critical modules or executing scripts).

* The interface must be responsive and optimized for both touchscreen and desktop environments, with adaptive layout behavior.

* All state updates and feedback displayed in the frontend must be driven by backend notifications or queries—no internal decision-making occurs in the frontend.

* Real-time communication (e.g., FSM state updates, sensor triggers, chat messages) should be handled via WebSockets for efficiency.

* Localization support should be considered to allow multi-language interfaces depending on the user’s profile settings.

* Frontend must gracefully handle backend disconnections, degraded module availability, or limited connectivity, and visually reflect system errors or degraded modes.

## 4. Technologies Used

* **Framework**: React (with TypeScript) as the core SPA framework.
* **Build Tool**: Vite for fast development and optimized production builds.
* **Styling**: Tailwind CSS for utility-first styling and responsive design.
* **Animations**: Framer Motion for state-based animations and smooth transitions.
* **UI Components**: ShadCN/UI for consistent, accessible component design.
* **Data Handling**: Axios or Fetch API for REST calls; native WebSocket for real-time events.
* **Routing**: React Router for internal navigation (if multi-view is required).
* **State Management**: React Context API or Zustand for lightweight client-side state.
* **Testing**: Vitest and React Testing Library for unit and integration testing.
* **Security**: Role validation on route and component level; JWT or token-based session validation via backend.

## 4. Technologies Used

* **Framework**: React (with TypeScript) as the core SPA framework.
* **Build Tool**: Vite for fast development and optimized production builds.
* **Styling**: Tailwind CSS for utility-first styling and responsive design.
* **Animations**: Framer Motion for state-based animations and smooth transitions.
* **UI Components**: ShadCN/UI for consistent, accessible component design.
* **Data Handling**: Axios or Fetch API for REST calls; native WebSocket for real-time events.
* **Routing**: React Router for internal navigation (if multi-view is required).
* **State Management**: React Context API or Zustand for lightweight client-side state.
* **Testing**: Vitest and React Testing Library for unit and integration testing.
* **Security**: Role validation on route and component level; JWT or token-based session validation via backend.

---

## 5. Inputs from Other Modules

All data received by the frontend is routed and structured through the `backend/`, which acts as the central orchestrator and API layer. The frontend never communicates directly with low-level modules, sensors, or scripts.

* **FSM and System Control (via `backend/`)**:

  * FSM state and transition labels (from `fsm_controller/` embedded in backend)
  * System messages, alerts, and error feedback
  * Session state, user role, authentication tokens
  * Status and availability of system modules (voice, sensors, vision, agents)

* **Sensor and Environment Data (via `backend/`)**:

  * Motion and presence detection (PIR, camera, IMU)
  * Environmental readings (temperature, humidity, sound levels)
  * Peripheral inputs (NFC tag IDs, Bluetooth devices, WiFi presence)
  * Real-time data streams or aggregated summaries (depending on role)

* **Voice Processing (via `backend/`)**:

  * Transcribed speech input from STT
  * TTS playback acknowledgements or failures

* **Agent and Contextual Intelligence (via `backend/`)**:

  * Agent-generated prompts, warnings, or decisions based on combined data
  * Contextual labels (e.g., user attention, estimated mood, behavioral patterns)

* **Logs and History (via `backend/`)**:

  * Interaction history, command logs, usage statistics
  * Access controlled based on user role

---

## 6. Outputs to Other Modules and Environment

* **To `backend/`**:

  * User-generated events (e.g. button presses, chat commands, configuration actions)
  * Session authentication requests (login, logout, role validation)
  * Requests to trigger voice interaction (start/stop listening)
  * Admin requests to control modules (activate/deactivate sensors, run diagnostics, update configuration)

* **To the user (environment)**:

  * Visual feedback of system status, voice processing, and sensor events
  * Interactive chat interface (secondary to voice)
  * Animations, state indicators, or UI prompts depending on FSM state
  * Access to logs or usage metrics (authorized roles only)

All outputs are transmitted through the backend, which then dispatches them to the relevant subsystems or processes. The frontend never interacts directly with physical devices or AI modules.

## 7. Internal Structure (Frontend)

The internal structure of the `frontend/` module is organized into a modular and reactive component hierarchy, designed to support scalability, clarity, and role-based customization:

* **Main View Layer**:

  * Dashboard or Home view, dynamically rendered based on user role.
  * Chat interface panel (optional, role-dependent).
  * Context-aware status area showing FSM state, sensor feedback, and system prompts.

* **Navigation and Layout**:

  * Top-level navigation bar or menu for role-based access to features.
  * Modular layout using reusable containers and views.

* **Event Dispatcher**:

  * Captures all user interactions and forwards them to the backend via WebSocket or REST.
  * Wraps user actions with context metadata (timestamp, role, device info).

* **State Manager**:

  * Tracks frontend-specific UI state (active view, loading indicators, UI mode).
  * Integrates with backend-provided state such as current FSM or session info.

* **Role-Based Renderer**:

  * Conditionally loads components based on current user role (admin, user, guest).
  * Hides or disables unauthorized actions and views.

* **WebSocket Listener**:

  * Subscribes to backend push updates (FSM changes, sensor events, agent messages).
  * Updates local components and triggers visual feedback.

* **Styling and Animation Layer**:

  * Tailwind CSS utilities for layout, theming, responsiveness.
  * Framer Motion integration for animated transitions and system reactions.

This structure ensures that the frontend remains responsive, reactive, and user-aware, while delegating all system logic and processing to the backend.
